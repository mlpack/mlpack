## `TSNE`

The `TSNE` class implements t-distributed Stochastic Neighbor Embedding
(t-SNE), a nonlinear dimensionality reduction technique designed mainly for
visualization. It captures pairwise similarities in the high-dimensional space
and finds a low-dimensional representation that preserves them.

The t-SNE algorithm works in two stages. First, it builds a probability
distribution over pairs of points in the high-dimensional space using a
Gaussian kernel, assigning higher probabilities to closer points and lower
probabilities to farther ones. Second, it models pairwise similarities in the
low-dimensional space with a heavy-tailed Student’s t-distribution and adjusts
point positions by minimizing the Kullback–Leibler (KL) divergence between the
two distributions using gradient descent.

This implementation provides multiple strategies for computing the KL
divergence and its gradient. (see [methods](#methods) for more detail)

#### Simple usage example

```c++
// Use t-SNE to reduce the number of dimensions to 2 on some dataset.
// Replace with a data::Load() call or similar for a real application.
arma::mat dataset(10, 1000, arma::fill::randu); // 1000 points in 10d.

// Step 1: create TSNE object (using defaults).
mlpack::TSNE<> tsne;

// Step 2: embed data into 2 dimensions.
arma::mat output;
tsne.Embed(dataset, output);

// Print some information about the modified dataset.
std::cout << "The transformed data matrix has size " << output.n_rows /* 2 */
    << " x " << output.n_cols << "." << std::endl;
```
<p style="text-align: center; font-size: 85%"><a href="#examples">More examples...</a></p>

#### Quick links

- [Constructors](#constructors): create `TSNE` objects.
- [`Embed()`](#embed): embed data into a lower-dimensional space.
- [Examples](#examples) of simple usage and links to detailed example
   projects.
- [Template parameters](#methods) for using different gradient computation
   methods.

#### See also

- [mlpack transformations](../transformations.md)
- [`PCA`](pca.md): principal components analysis
- [t-distributed Stochastic Neighbor Embedding on Wikipedia](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding)

### Constructors

- `tsne = TSNE(outputDim=2, perplexity=30.0, exaggeration=12.0, learningRate=200.0, maxIter=1000, init="pca", theta=0.5)`  
  - `outputDim`: Dimensionality of the embedded space. *(Default: 2)*  
  - `perplexity`: Regulates the balance between local and global structure preservation. Typically set between 5 and 50. *(Default: 30.0)*  
  - `exaggeration`: Amplifies pairwise similarities during the initial optimization phase, forming tighter clusters and clearer separation. A higher value increases spacing between clusters, but if the cost grows during initial iterations, reduce this value or lower the learning rate. *(Default: 12.0)*  
  - `learningRate`: Learning rate (step size) for the optimizer. If set to `0`, it is computed as `N / exaggeration` each time `Embed` is called. *(Default: 200.0)*  
  - `maxIter`: Maximum number of iterations. *(Default: 1000)*  
  - `init`: Initialization method for the embedding. Options: `"random"`, `"pca"`. PCA initialization is recommended for speed and quality. *(Default: `"pca"`)*  
  - `theta`: Trade-off between speed and accuracy for `"barnes_hut"` and `"dual_tree"` approximations. Optimal value depends on the chosen method. *(Default: 0.5)*  

---

### Embed Overloads

- `tsne.Embed(X, Y)`
  - Embed the [column-major matrix](../matrices.md#representing-data-in-mlpack) `X`
     into a lower-dimensional space, storing the result in `Y`.
  - `X` should be a floating-point matrix (e.g. `arma::mat`, `arma::fmat`,
     etc.) or an expression that evaluates to one.
  - `Y` will be overwritten with the output embedding, and will have
     `outputDim` rows.

---

### Examples

See also the [simple usage example](#simple-usage-example) for a trivial usage
of the `TSNE` class.

---

Embed a dataset into 3 dimensions using the dual-tree method.

```c++
// See https://datasets.mlpack.org/iris.csv.
arma::mat data;
mlpack::data::Load("satellite.train.csv", data, true);

// Use the dual-tree approximation and embed to 3 dimensions.
mlpack::TSNE<mlpack::DualTreeTSNE> tsne(3);

arma::mat output;
tsne.Embed(data, output);

mlpack::data::Save("satellite.train.3d.csv", output, true);
```

---

Embed a dataset, with custom parameters.

```c++
// See https://datasets.mlpack.org/satellite.train.csv.
arma::mat data;
mlpack::data::Load("satellite.train.csv", data, true);

// Specify a perplexity of 50 and 1500 iterations.
mlpack::TSNE<> tsne(2, 50.0, 12.0, 200.0, 1500);

arma::mat output;
tsne.Embed(data, output);

mlpack::data::Save("satellite.train.3d.csv", output, true);
```

---

### Methods

By default, `TSNE` uses the Barnes-Hut method to approximate the gradient
calculation.  However, for smaller datasets, it may be possible to use the exact
method, and for some situations the dual-tree approximation may be preferable.
The `TSNE` class has a template parameter `TSNEMethod` that allows different gradient
computation strategies to be used.  The full signature of the class is:

```
TSNE<TSNEMethod>
```

`TSNEMethod` specifies the TSNEMethod to be used to compute the t-SNE gradient.

These methods are already implemented and ready for drop-in usage:

- `ExactTSNE`
  - Computes the exact gradient of the t-SNE objective.  
  - Time Complexity: O(N^2).
  - Provides the most accurate results but quickly becomes impractical for large
    datasets (e.g., beyond a few thousand points).  
  - Use when dataset size is small and exact precision is required.  

- `BarnesHutTSNE` _(default)_  
  - Uses the Barnes-Hut approximation for computing the gradient.
  - Time Complexity: O(NlogN).  
  - Produces high-quality embeddings much faster than the exact method.  
  - Works well for medium to large datasets and is the most commonly used method in
  practice.

- `DualTreeTSNE`
  - Uses a dual-tree based approximation for computing the gradient.  
  - Time Complexity: O(NlogN).
  - Can be faster than Barnes-Hut in certain scenarios, especially for
    higher-dimensional embeddings.  
  - Useful when Barnes-Hut performance starts degrading with increasing dataset size
    or dimensionality.
  
The simple example program below uses all three strategies on the same
data, timing how long each one takes.

```c++
arma::mat data;
// See https://datasets.mlpack.org/mnist.train.csv.
// Note: this is a large dataset and may take a while.
mlpack::data::Load("mnist.train.csv", data, true);

arma::mat output1, output2, output3;

mlpack::TSNE<mlpack::BarnesHutTSNE> tsne1;
mlpack::TSNE<mlpack::DualTreeTSNE> tsne2;
mlpack::TSNE<mlpack::ExactTSNE> tsne3;

// Compute embeddings with all three, timing each one.
arma::wall_clock c;

c.tic();
tsne1.Embed(data, output1);
const double tsne1Time = c.toc();

c.tic();
tsne2.Embed(data, output2);
const double tsne2Time = c.toc();

c.tic();
tsne3.Embed(data, output3);
const double tsne3Time = c.toc();

std::cout << "t-SNE computation times for " << data.n_rows << " x " << data.n_cols
    << " data:" << std::endl;
std::cout << " - BarnesHutTSNE: " << tsne1Time << "s." << std::endl;
std::cout << " - DualTreeTSNE:  " << tsne2Time << "s." << std::endl;
std::cout << " - ExactTSNE:     " << tsne3Time << "s." << std::endl;
```
