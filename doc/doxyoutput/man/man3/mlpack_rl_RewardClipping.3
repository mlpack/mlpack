.TH "RewardClipping< EnvironmentType >" 3 "Sun Jun 20 2021" "Version 3.4.2" "mlpack" \" -*- nroff -*-
.ad l
.nh
.SH NAME
RewardClipping< EnvironmentType > \- Interface for clipping the reward to some value between the specified maximum and minimum value (Clipping here is implemented as $ g_{\text{clipped}} = \max(g_{\text{min}}, \min(g_{\text{min}}, g))) $\&.)  

.SH SYNOPSIS
.br
.PP
.SS "Public Types"

.in +1c
.ti -1c
.RI "using \fBAction\fP = typename EnvironmentType::Action"
.br
.RI "Convenient typedef for action\&. "
.ti -1c
.RI "using \fBState\fP = typename EnvironmentType::State"
.br
.RI "Convenient typedef for state\&. "
.in -1c
.SS "Public Member Functions"

.in +1c
.ti -1c
.RI "\fBRewardClipping\fP (EnvironmentType &environment, const double minReward=\-1\&.0, const double maxReward=1\&.0)"
.br
.RI "Constructor for creating a \fBRewardClipping\fP instance\&. "
.ti -1c
.RI "EnvironmentType & \fBEnvironment\fP ()"
.br
.RI "Modify the environment\&. "
.ti -1c
.RI "EnvironmentType & \fBEnvironment\fP () const"
.br
.RI "Get the environment\&. "
.ti -1c
.RI "\fBState\fP \fBInitialSample\fP ()"
.br
.RI "The InitialSample method is called by the environment to initialize the starting state\&. "
.ti -1c
.RI "bool \fBIsTerminal\fP (const \fBState\fP &state) const"
.br
.RI "Checks whether given state is a terminal state\&. "
.ti -1c
.RI "double & \fBMaxReward\fP ()"
.br
.RI "Modify the maximum reward value\&. "
.ti -1c
.RI "double \fBMaxReward\fP () const"
.br
.RI "Get the maximum reward value\&. "
.ti -1c
.RI "double & \fBMinReward\fP ()"
.br
.RI "Modify the minimum reward value\&. "
.ti -1c
.RI "double \fBMinReward\fP () const"
.br
.RI "Get the minimum reward value\&. "
.ti -1c
.RI "double \fBSample\fP (const \fBState\fP &state, const \fBAction\fP &action)"
.br
.RI "Dynamics of Environment\&. "
.ti -1c
.RI "double \fBSample\fP (const \fBState\fP &state, const \fBAction\fP &action, \fBState\fP &nextState)"
.br
.RI "Dynamics of Environment\&. "
.in -1c
.SH "Detailed Description"
.PP 

.SS "template<typename EnvironmentType>
.br
class mlpack::rl::RewardClipping< EnvironmentType >"
Interface for clipping the reward to some value between the specified maximum and minimum value (Clipping here is implemented as $ g_{\text{clipped}} = \max(g_{\text{min}}, \min(g_{\text{min}}, g))) $\&.) 


.PP
\fBTemplate Parameters\fP
.RS 4
\fIEnvironmentType\fP A type of Environment that is being wrapped\&. 
.RE
.PP

.PP
Definition at line 30 of file reward_clipping\&.hpp\&.
.SH "Member Typedef Documentation"
.PP 
.SS "using \fBAction\fP =  typename EnvironmentType::Action"

.PP
Convenient typedef for action\&. 
.PP
Definition at line 37 of file reward_clipping\&.hpp\&.
.SS "using \fBState\fP =  typename EnvironmentType::State"

.PP
Convenient typedef for state\&. 
.PP
Definition at line 34 of file reward_clipping\&.hpp\&.
.SH "Constructor & Destructor Documentation"
.PP 
.SS "\fBRewardClipping\fP (EnvironmentType & environment, const double minReward = \fC\-1\&.0\fP, const double maxReward = \fC1\&.0\fP)\fC [inline]\fP"

.PP
Constructor for creating a \fBRewardClipping\fP instance\&. 
.PP
\fBParameters\fP
.RS 4
\fIminReward\fP Minimum possible value of clipped reward\&. 
.br
\fImaxReward\fP Maximum possible value of clipped reward\&. 
.br
\fIenvironment\fP An instance of the environment used for actual simulations\&. 
.RE
.PP

.PP
Definition at line 47 of file reward_clipping\&.hpp\&.
.SH "Member Function Documentation"
.PP 
.SS "EnvironmentType& Environment ()\fC [inline]\fP"

.PP
Modify the environment\&. 
.PP
Definition at line 115 of file reward_clipping\&.hpp\&.
.SS "EnvironmentType& Environment () const\fC [inline]\fP"

.PP
Get the environment\&. 
.PP
Definition at line 113 of file reward_clipping\&.hpp\&.
.SS "\fBState\fP InitialSample ()\fC [inline]\fP"

.PP
The InitialSample method is called by the environment to initialize the starting state\&. Returns whatever Initial Sample is returned by the environment\&. 
.PP
Definition at line 62 of file reward_clipping\&.hpp\&.
.SS "bool IsTerminal (const \fBState\fP & state) const\fC [inline]\fP"

.PP
Checks whether given state is a terminal state\&. Returns the value by calling the environment method\&.
.PP
\fBParameters\fP
.RS 4
\fIstate\fP desired state\&. 
.RE
.PP
\fBReturns\fP
.RS 4
true if state is a terminal state, otherwise false\&. 
.RE
.PP

.PP
Definition at line 74 of file reward_clipping\&.hpp\&.
.SS "double& MaxReward ()\fC [inline]\fP"

.PP
Modify the maximum reward value\&. 
.PP
Definition at line 125 of file reward_clipping\&.hpp\&.
.SS "double MaxReward () const\fC [inline]\fP"

.PP
Get the maximum reward value\&. 
.PP
Definition at line 123 of file reward_clipping\&.hpp\&.
.SS "double& MinReward ()\fC [inline]\fP"

.PP
Modify the minimum reward value\&. 
.PP
Definition at line 120 of file reward_clipping\&.hpp\&.
.SS "double MinReward () const\fC [inline]\fP"

.PP
Get the minimum reward value\&. 
.PP
Definition at line 118 of file reward_clipping\&.hpp\&.
.SS "double Sample (const \fBState\fP & state, const \fBAction\fP & action)\fC [inline]\fP"

.PP
Dynamics of Environment\&. The rewards returned from the base environment are clipped according the maximum and minimum values specified\&.
.PP
\fBParameters\fP
.RS 4
\fIstate\fP The current state\&. 
.br
\fIaction\fP The current action\&. 
.RE
.PP
\fBReturns\fP
.RS 4
clippedReward, Reward clipped between [minReward, maxReward]\&. 
.RE
.PP

.PP
Definition at line 106 of file reward_clipping\&.hpp\&.
.PP
References RewardClipping< EnvironmentType >::Sample()\&.
.SS "double Sample (const \fBState\fP & state, const \fBAction\fP & action, \fBState\fP & nextState)\fC [inline]\fP"

.PP
Dynamics of Environment\&. The rewards returned from the base environment are clipped according the maximum and minimum values specified\&.
.PP
\fBParameters\fP
.RS 4
\fIstate\fP The current state\&. 
.br
\fIaction\fP The current action\&. 
.br
\fInextState\fP The next state\&. 
.RE
.PP
\fBReturns\fP
.RS 4
clippedReward, Reward clipped between [minReward, maxReward]\&. 
.RE
.PP

.PP
Definition at line 88 of file reward_clipping\&.hpp\&.
.PP
References mlpack::math::ClampRange()\&.
.PP
Referenced by RewardClipping< EnvironmentType >::Sample()\&.

.SH "Author"
.PP 
Generated automatically by Doxygen for mlpack from the source code\&.
