.TH "HyperParameterTuner< MLAlgorithm, Metric, CV, OptimizerType, MatType, PredictionsType, WeightsType >" 3 "Sun Jun 20 2021" "Version 3.4.2" "mlpack" \" -*- nroff -*-
.ad l
.nh
.SH NAME
HyperParameterTuner< MLAlgorithm, Metric, CV, OptimizerType, MatType, PredictionsType, WeightsType > \- The class \fBHyperParameterTuner\fP for the given MLAlgorithm utilizes the provided Optimizer to find the values of hyper-parameters that optimize the value of the given Metric\&.  

.SH SYNOPSIS
.br
.PP
.SS "Public Member Functions"

.in +1c
.ti -1c
.RI "template<typename\&.\&.\&. CVArgs> \fBHyperParameterTuner\fP (const CVArgs &\&.\&.\&.args)"
.br
.RI "Create a \fBHyperParameterTuner\fP object by passing constructor arguments for the given cross-validation strategy (the CV class)\&. "
.ti -1c
.RI "MLAlgorithm & \fBBestModel\fP ()"
.br
.RI "Modify the best model from the last run\&. "
.ti -1c
.RI "const MLAlgorithm & \fBBestModel\fP () const"
.br
.RI "Get the best model from the last run\&. "
.ti -1c
.RI "double \fBBestObjective\fP () const"
.br
.RI "Get the performance measurement of the best model from the last run\&. "
.ti -1c
.RI "double & \fBMinDelta\fP ()"
.br
.RI "Modify minimum increase of arguments for calculation of partial derivatives (by the definition) in gradient-based optimization\&. "
.ti -1c
.RI "double \fBMinDelta\fP () const"
.br
.RI "Get minimum increase of arguments for calculation of partial derivatives (by the definition) in gradient-based optimization\&. "
.ti -1c
.RI "template<typename\&.\&.\&. Args> \fBTupleOfHyperParameters\fP< Args\&.\&.\&. > \fBOptimize\fP (const Args &\&.\&.\&. args)"
.br
.RI "Find the best hyper-parameters by using the given Optimizer\&. "
.ti -1c
.RI "OptimizerType & \fBOptimizer\fP ()"
.br
.RI "Access and modify the optimizer\&. "
.ti -1c
.RI "double & \fBRelativeDelta\fP ()"
.br
.RI "Modify relative increase of arguments for calculation of partial derivatives (by the definition) in gradient-based optimization\&. "
.ti -1c
.RI "double \fBRelativeDelta\fP () const"
.br
.RI "Get relative increase of arguments for calculation of partial derivatives (by the definition) in gradient-based optimization\&. "
.in -1c
.SH "Detailed Description"
.PP 

.SS "template<typename MLAlgorithm, typename Metric, template< typename, typename, typename, typename, typename > class CV, typename OptimizerType = ens::GridSearch, typename MatType = arma::mat, typename PredictionsType = typename cv::MetaInfoExtractor<MLAlgorithm,                 MatType>::PredictionsType, typename WeightsType = typename cv::MetaInfoExtractor<MLAlgorithm, MatType,                 PredictionsType>::WeightsType>
.br
class mlpack::hpt::HyperParameterTuner< MLAlgorithm, Metric, CV, OptimizerType, MatType, PredictionsType, WeightsType >"
The class \fBHyperParameterTuner\fP for the given MLAlgorithm utilizes the provided Optimizer to find the values of hyper-parameters that optimize the value of the given Metric\&. 

The value of the Metric is calculated by performing cross-validation with the provided cross-validation strategy\&.
.PP
To construct a \fBHyperParameterTuner\fP object you need to pass the same arguments as for construction of an object of the given CV class\&. For example, we can use the following code to try to find a good lambda value for LinearRegression\&.
.PP
.PP
.nf
// 100-point 5-dimensional random dataset\&.
arma::mat data = arma::randu<arma::mat>(5, 100);
// Noisy responses retrieved by a random linear transformation of data\&.
arma::rowvec responses = arma::randu<arma::rowvec>(5) * data +
    0\&.1 * arma::randn<arma::rowvec>(100);

// Using 80% of data for training and remaining 20% for assessing MSE\&.
double validationSize = 0\&.2;
HyperParameterTuner<LinearRegression, MSE, SimpleCV> hpt(validationSize,
    data, responses);

// Finding the best value for lambda from the values 0\&.0, 0\&.001, 0\&.01, 0\&.1,
// and 1\&.0\&.
arma::vec lambdas{0\&.0, 0\&.001, 0\&.01, 0\&.1, 1\&.0};
double bestLambda;
std::tie(bestLambda) = hpt\&.Optimize(lambdas);
.fi
.PP
.PP
When some hyper-parameters should not be optimized, you can specify values for them with the Fixed function as in the following example of finding good lambda1 and lambda2 values for LARS\&.
.PP
.PP
.nf
HyperParameterTuner<LARS, MSE, SimpleCV> hpt2(validationSize, data,
    responses);

bool transposeData = true;
bool useCholesky = false;
arma::vec lambda1Set{0\&.0, 0\&.001, 0\&.01, 0\&.1, 1\&.0};
arma::vec lambda2Set{0\&.0, 0\&.002, 0\&.02, 0\&.2, 2\&.0};

double bestLambda1, bestLambda2;
std::tie(bestLambda1, bestLambda2) = hpt2\&.Optimize(Fixed(transposeData),
    Fixed(useCholesky), lambda1Set, lambda2Set);
.fi
.PP
.PP
\fBTemplate Parameters\fP
.RS 4
\fIMLAlgorithm\fP A machine learning algorithm\&. 
.br
\fIMetric\fP A metric to assess the quality of a trained model\&. 
.br
\fICV\fP A cross-validation strategy used to assess a set of hyper-parameters\&. 
.br
\fIOptimizerType\fP An optimization strategy (GridSearch and GradientDescent are supported)\&. 
.br
\fIMatType\fP The type of data\&. 
.br
\fIPredictionsType\fP The type of predictions (should be passed when the predictions type is a template parameter in Train methods of the given MLAlgorithm; arma::Row<size_t> will be used otherwise)\&. 
.br
\fIWeightsType\fP The type of weights (should be passed when weighted learning is supported, and the weights type is a template parameter in Train methods of the given MLAlgorithm; arma::vec will be used otherwise)\&. 
.RE
.PP

.PP
Definition at line 96 of file hpt\&.hpp\&.
.SH "Constructor & Destructor Documentation"
.PP 
.SS "\fBHyperParameterTuner\fP (const CVArgs &\&.\&.\&. args)"

.PP
Create a \fBHyperParameterTuner\fP object by passing constructor arguments for the given cross-validation strategy (the CV class)\&. 
.PP
\fBParameters\fP
.RS 4
\fIargs\fP Constructor arguments for the given cross-validation strategy (the CV class)\&. 
.RE
.PP

.SH "Member Function Documentation"
.PP 
.SS "MLAlgorithm& BestModel ()\fC [inline]\fP"

.PP
Modify the best model from the last run\&. 
.PP
Definition at line 187 of file hpt\&.hpp\&.
.SS "const MLAlgorithm& BestModel () const\fC [inline]\fP"

.PP
Get the best model from the last run\&. 
.PP
Definition at line 184 of file hpt\&.hpp\&.
.SS "double BestObjective () const\fC [inline]\fP"

.PP
Get the performance measurement of the best model from the last run\&. 
.PP
Definition at line 181 of file hpt\&.hpp\&.
.SS "double& MinDelta ()\fC [inline]\fP"

.PP
Modify minimum increase of arguments for calculation of partial derivatives (by the definition) in gradient-based optimization\&. This value is going to be used when it is greater than the increase calculated with the rules described in the documentation for \fBRelativeDelta()\fP\&.
.PP
The default value is 1e-10\&. 
.PP
Definition at line 152 of file hpt\&.hpp\&.
.SS "double MinDelta () const\fC [inline]\fP"

.PP
Get minimum increase of arguments for calculation of partial derivatives (by the definition) in gradient-based optimization\&. This value is going to be used when it is greater than the increase calculated with the rules described in the documentation for \fBRelativeDelta()\fP\&.
.PP
The default value is 1e-10\&. 
.PP
Definition at line 142 of file hpt\&.hpp\&.
.SS "\fBTupleOfHyperParameters\fP<Args\&.\&.\&.> Optimize (const Args &\&.\&.\&. args)"

.PP
Find the best hyper-parameters by using the given Optimizer\&. For each hyper-parameter one of the following should be passed as an argument\&.
.IP "1." 4
A set of values to choose from (when using GridSearch as an optimizer)\&. The set of values should be an STL-compatible container (it should provide begin() and end() methods returning iterators)\&.
.IP "2." 4
A starting value (when using any other optimizer than GridSearch)\&.
.IP "3." 4
A value fixed by using the function \fBmlpack::hpt::Fixed\fP\&. In this case the hyper-parameter will not be optimized\&.
.PP
.PP
All arguments should be passed in the same order as if the corresponding hyper-parameters would be passed into the Evaluate method of the given CV class (in the order as they appear in the constructor(s) of the given MLAlgorithm)\&. Also, arguments for all required hyper-parameters (ones that don't have default values in the corresponding MLAlgorithm constructor) should be provided\&.
.PP
The method returns a tuple of values for hyper-parameters that haven't been fixed\&.
.PP
\fBParameters\fP
.RS 4
\fIargs\fP Arguments corresponding to hyper-parameters (see the method description for more information)\&. 
.RE
.PP

.SS "OptimizerType& Optimizer ()\fC [inline]\fP"

.PP
Access and modify the optimizer\&. 
.PP
Definition at line 110 of file hpt\&.hpp\&.
.SS "double& RelativeDelta ()\fC [inline]\fP"

.PP
Modify relative increase of arguments for calculation of partial derivatives (by the definition) in gradient-based optimization\&. The exact increase for some particular argument is equal to the absolute value of the argument multiplied by the relative increase (see also the documentation for \fBMinDelta()\fP)\&.
.PP
The default value is 0\&.01\&. 
.PP
Definition at line 132 of file hpt\&.hpp\&.
.SS "double RelativeDelta () const\fC [inline]\fP"

.PP
Get relative increase of arguments for calculation of partial derivatives (by the definition) in gradient-based optimization\&. The exact increase for some particular argument is equal to the absolute value of the argument multiplied by the relative increase (see also the documentation for \fBMinDelta()\fP)\&.
.PP
The default value is 0\&.01\&. 
.PP
Definition at line 121 of file hpt\&.hpp\&.

.SH "Author"
.PP 
Generated automatically by Doxygen for mlpack from the source code\&.
