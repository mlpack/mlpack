\doxysection{HMMRegression Class Reference}
\label{classmlpack_1_1hmm_1_1HMMRegression}\index{HMMRegression@{HMMRegression}}


A class that represents a Hidden Markov Model Regression (HMMR).  




Inheritance diagram for HMMRegression\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=244pt]{classmlpack_1_1hmm_1_1HMMRegression__inherit__graph}
\end{center}
\end{figure}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\textbf{ HMMRegression} (const arma\+::vec \&initial, const arma\+::mat \&transition, const std\+::vector$<$ \textbf{ distribution\+::\+Regression\+Distribution} $>$ \&\textbf{ emission}, const double tolerance=1e-\/5)
\begin{DoxyCompactList}\small\item\em Create the Hidden Markov Model Regression with the given initial probability vector, the given transition matrix, and the given regression emission distributions. \end{DoxyCompactList}\item 
\textbf{ HMMRegression} (const size\+\_\+t states, const \textbf{ distribution\+::\+Regression\+Distribution} emissions, const double tolerance=1e-\/5)
\begin{DoxyCompactList}\small\item\em Create the Hidden Markov Model Regression with the given number of hidden states and the given default regression emission. \end{DoxyCompactList}\item 
double \textbf{ Estimate} (const arma\+::mat \&predictors, const arma\+::vec \&responses, arma\+::mat \&state\+Prob) const
\begin{DoxyCompactList}\small\item\em Estimate the probabilities of each hidden state at each time step of each given data observation, using the Forward-\/\+Backward algorithm. \end{DoxyCompactList}\item 
double \textbf{ Estimate} (const arma\+::mat \&predictors, const arma\+::vec \&responses, arma\+::mat \&state\+Prob, arma\+::mat \&forward\+Prob, arma\+::mat \&backward\+Prob, arma\+::vec \&scales) const
\begin{DoxyCompactList}\small\item\em Estimate the probabilities of each hidden state at each time step for each given data observation, using the Forward-\/\+Backward algorithm. \end{DoxyCompactList}\item 
void \textbf{ Filter} (const arma\+::mat \&predictors, const arma\+::vec \&responses, arma\+::vec \&filter\+Seq, size\+\_\+t ahead=0) const
\begin{DoxyCompactList}\small\item\em HMMR filtering. \end{DoxyCompactList}\item 
double \textbf{ Log\+Likelihood} (const arma\+::mat \&predictors, const arma\+::vec \&responses) const
\begin{DoxyCompactList}\small\item\em Compute the log-\/likelihood of the given predictors and responses. \end{DoxyCompactList}\item 
double \textbf{ Predict} (const arma\+::mat \&predictors, const arma\+::vec \&responses, arma\+::\+Row$<$ size\+\_\+t $>$ \&state\+Seq) const
\begin{DoxyCompactList}\small\item\em Compute the most probable hidden state sequence for the given predictors and responses, using the Viterbi algorithm, returning the log-\/likelihood of the most likely state sequence. \end{DoxyCompactList}\item 
void \textbf{ Smooth} (const arma\+::mat \&predictors, const arma\+::vec \&responses, arma\+::vec \&smooth\+Seq) const
\begin{DoxyCompactList}\small\item\em \doxyref{HMM}{p.}{classmlpack_1_1hmm_1_1HMM} smoothing. \end{DoxyCompactList}\item 
void \textbf{ Train} (const std\+::vector$<$ arma\+::mat $>$ \&predictors, const std\+::vector$<$ arma\+::vec $>$ \&responses)
\begin{DoxyCompactList}\small\item\em Train the model using the Baum-\/\+Welch algorithm, with only the given predictors and responses. \end{DoxyCompactList}\item 
void \textbf{ Train} (const std\+::vector$<$ arma\+::mat $>$ \&predictors, const std\+::vector$<$ arma\+::vec $>$ \&responses, const std\+::vector$<$ arma\+::\+Row$<$ size\+\_\+t $>$ $>$ \&state\+Seq)
\begin{DoxyCompactList}\small\item\em Train the model using the given labeled observations; the transition and regression emissions are directly estimated. \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsection*{Additional Inherited Members}


\doxysubsection{Detailed Description}
A class that represents a Hidden Markov Model Regression (HMMR). 

HMMR is an extension of Hidden Markov Models to regression analysis. The method is described in (Fridman, 1993) {\texttt{ https\+://www.\+ima.\+umn.\+edu/preprints/\+January1994/1195.\+pdf}} An HMMR is a linear regression model whose coefficients are determined by a finite-\/state Markov chain. The error terms are conditionally independently normally distributed with zero mean and state-\/dependent variance. Let Q\+\_\+t be a finite-\/state Markov chain, X\+\_\+t a vector of predictors and Y\+\_\+t a response. The HMMR is $ Y_t = X_t \beta_{Q_t} + \sigma_{Q_t} \epsilon_t $

This HMMR class supports training (supervised and unsupervised), prediction of state sequences via the Viterbi algorithm, estimation of state probabilities, filtering and smoothing of responses, and calculation of the log-\/likelihood of a given sequence.

Usage of the HMMR class generally involves either training an HMMR or loading an already-\/known HMMR and using to filter a sequence. Example code for supervised training of an HMMR is given below.


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{comment}{// Each column is a vector of predictors for a single observation.}}
\DoxyCodeLine{arma::mat predictors(5, 100, arma::fill::randn);}
\DoxyCodeLine{\textcolor{comment}{// Responses for each observation}}
\DoxyCodeLine{arma::vec responses(100, arma::fill::randn);}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{// Create an untrained HMMR with 3 hidden states}}
\DoxyCodeLine{RegressionDistribution rd(predictors, responses);}
\DoxyCodeLine{arma::mat transition(\textcolor{stringliteral}{"{}0.5 0.5;"{}} \textcolor{stringliteral}{"{}0.5 0.5;"{}});}
\DoxyCodeLine{std::vector<RegressionDistribution> emissions(2,rd);}
\DoxyCodeLine{HMMRegression hmmr(\textcolor{stringliteral}{"{}0.9 0.1"{}}, transition, emissions);}
\DoxyCodeLine{}
\DoxyCodeLine{ \textcolor{comment}{// Train the HMM (supply a state sequence to perform supervised training)}}
\DoxyCodeLine{std::vector<arma::mat> predictorsSeq(1, predictors);}
\DoxyCodeLine{std::vector< arma::vec> responsesSeq(1, responses);}
\DoxyCodeLine{hmmr.Train(predictorsSeq, responsesSeq);}
\DoxyCodeLine{hmm.Train(observations, states);}

\end{DoxyCode}


Once initialized, the HMMR can evaluate the probability of a certain sequence (with \doxyref{Log\+Likelihood()}{p.}{classmlpack_1_1hmm_1_1HMMRegression_a5e7c4dbe9cfacdf2746e92cd20aa2a66}), predict the most likely sequence of hidden states (with \doxyref{Predict()}{p.}{classmlpack_1_1hmm_1_1HMMRegression_a039bc421248d00ffae03def696c0cfbd}), estimate the probabilities of each state for a sequence of observations (with \doxyref{Estimate()}{p.}{classmlpack_1_1hmm_1_1HMMRegression_a58cd0299f6951072a3ae4a10cf698853}), or perform filtering or smoothing of observations. 

Definition at line 69 of file hmm\+\_\+regression.\+hpp.



\doxysubsection{Constructor \& Destructor Documentation}
\mbox{\label{classmlpack_1_1hmm_1_1HMMRegression_a9a4d1ee17c46d307ed09f2e769d77421}} 
\index{HMMRegression@{HMMRegression}!HMMRegression@{HMMRegression}}
\index{HMMRegression@{HMMRegression}!HMMRegression@{HMMRegression}}
\doxysubsubsection{HMMRegression()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \textbf{ HMMRegression} (\begin{DoxyParamCaption}\item[{const size\+\_\+t}]{states,  }\item[{const \textbf{ distribution\+::\+Regression\+Distribution}}]{emissions,  }\item[{const double}]{tolerance = {\ttfamily 1e-\/5} }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Create the Hidden Markov Model Regression with the given number of hidden states and the given default regression emission. 

The dimensionality of the observations is taken from the emissions variable, so it is important that the given default emission distribution is set with the correct dimensionality. Alternately, set the dimensionality with \doxyref{Dimensionality()}{p.}{classmlpack_1_1hmm_1_1HMM_a787adc650f11b9430f6bd0b937bbe6b0}. Optionally, the tolerance for convergence of the Baum-\/\+Welch algorithm can be set.

By default, the transition matrix and initial probability vector are set to contain equal probability for each state.


\begin{DoxyParams}{Parameters}
{\em states} & Number of states. \\
\hline
{\em emissions} & Default distribution for emissions. \\
\hline
{\em tolerance} & Tolerance for convergence of training algorithm (Baum-\/\+Welch). \\
\hline
\end{DoxyParams}


Definition at line 89 of file hmm\+\_\+regression.\+hpp.

\mbox{\label{classmlpack_1_1hmm_1_1HMMRegression_a6322913bf387a716d9f4a7deeb14e969}} 
\index{HMMRegression@{HMMRegression}!HMMRegression@{HMMRegression}}
\index{HMMRegression@{HMMRegression}!HMMRegression@{HMMRegression}}
\doxysubsubsection{HMMRegression()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \textbf{ HMMRegression} (\begin{DoxyParamCaption}\item[{const arma\+::vec \&}]{initial,  }\item[{const arma\+::mat \&}]{transition,  }\item[{const std\+::vector$<$ \textbf{ distribution\+::\+Regression\+Distribution} $>$ \&}]{emission,  }\item[{const double}]{tolerance = {\ttfamily 1e-\/5} }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Create the Hidden Markov Model Regression with the given initial probability vector, the given transition matrix, and the given regression emission distributions. 

The dimensionality of the observations of the HMMR are taken from the given emission distributions. Alternately, the dimensionality can be set with \doxyref{Dimensionality()}{p.}{classmlpack_1_1hmm_1_1HMM_a787adc650f11b9430f6bd0b937bbe6b0}.

The initial state probability vector should have length equal to the number of states, and each entry represents the probability of being in the given state at time T = 0 (the beginning of a sequence).

The transition matrix should be such that T(i, j) is the probability of transition to state i from state j. The columns of the matrix should sum to 1.

Optionally, the tolerance for convergence of the Baum-\/\+Welch algorithm can be set.


\begin{DoxyParams}{Parameters}
{\em initial} & Initial state probabilities. \\
\hline
{\em transition} & Transition matrix. \\
\hline
{\em emission} & Emission distributions. \\
\hline
{\em tolerance} & Tolerance for convergence of training algorithm (Baum-\/\+Welch). \\
\hline
\end{DoxyParams}


Definition at line 119 of file hmm\+\_\+regression.\+hpp.



\doxysubsection{Member Function Documentation}
\mbox{\label{classmlpack_1_1hmm_1_1HMMRegression_a18a07e75d4611abb098bc01d3932bf20}} 
\index{HMMRegression@{HMMRegression}!Estimate@{Estimate}}
\index{Estimate@{Estimate}!HMMRegression@{HMMRegression}}
\doxysubsubsection{Estimate()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily double Estimate (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{predictors,  }\item[{const arma\+::vec \&}]{responses,  }\item[{arma\+::mat \&}]{state\+Prob }\end{DoxyParamCaption}) const}



Estimate the probabilities of each hidden state at each time step of each given data observation, using the Forward-\/\+Backward algorithm. 

The returned matrix of state probabilities has columns equal to the number of data observations, and rows equal to the number of hidden states in the model. The log-\/likelihood of the most probable sequence is returned.


\begin{DoxyParams}{Parameters}
{\em predictors} & Vector of predictor sequences. \\
\hline
{\em responses} & Vector of response sequences. \\
\hline
{\em state\+Prob} & Probabilities of each state at each time interval. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
Log-\/likelihood of most likely state sequence. 
\end{DoxyReturn}
\mbox{\label{classmlpack_1_1hmm_1_1HMMRegression_a58cd0299f6951072a3ae4a10cf698853}} 
\index{HMMRegression@{HMMRegression}!Estimate@{Estimate}}
\index{Estimate@{Estimate}!HMMRegression@{HMMRegression}}
\doxysubsubsection{Estimate()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily double Estimate (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{predictors,  }\item[{const arma\+::vec \&}]{responses,  }\item[{arma\+::mat \&}]{state\+Prob,  }\item[{arma\+::mat \&}]{forward\+Prob,  }\item[{arma\+::mat \&}]{backward\+Prob,  }\item[{arma\+::vec \&}]{scales }\end{DoxyParamCaption}) const}



Estimate the probabilities of each hidden state at each time step for each given data observation, using the Forward-\/\+Backward algorithm. 

Each matrix which is returned has columns equal to the number of data observations, and rows equal to the number of hidden states in the model. The log-\/likelihood of the most probable sequence is returned.


\begin{DoxyParams}{Parameters}
{\em predictors} & Vector of predictor sequences. \\
\hline
{\em responses} & Vector of response sequences. \\
\hline
{\em state\+Prob} & Matrix in which the probabilities of each state at each time interval will be stored. \\
\hline
{\em forward\+Prob} & Matrix in which the forward probabilities of each state at each time interval will be stored. \\
\hline
{\em backward\+Prob} & Matrix in which the backward probabilities of each state at each time interval will be stored. \\
\hline
{\em scales} & Vector in which the scaling factors at each time interval will be stored. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
Log-\/likelihood of most likely state sequence. 
\end{DoxyReturn}
\mbox{\label{classmlpack_1_1hmm_1_1HMMRegression_a4fabd58fdb7df6bcf221302569e0c05c}} 
\index{HMMRegression@{HMMRegression}!Filter@{Filter}}
\index{Filter@{Filter}!HMMRegression@{HMMRegression}}
\doxysubsubsection{Filter()}
{\footnotesize\ttfamily void Filter (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{predictors,  }\item[{const arma\+::vec \&}]{responses,  }\item[{arma\+::vec \&}]{filter\+Seq,  }\item[{size\+\_\+t}]{ahead = {\ttfamily 0} }\end{DoxyParamCaption}) const}



HMMR filtering. 

Computes the k-\/step-\/ahead expected response at each time conditioned only on prior observations. That is E\{ Y[t+k] $\vert$ Y[0], ..., Y[t] \}. The returned matrix has columns equal to the number of observations. Note that the expectation may not be meaningful for discrete emissions.


\begin{DoxyParams}{Parameters}
{\em predictors} & Vector of predictor sequences. \\
\hline
{\em responses} & Vector of response sequences. \\
\hline
{\em ahead} & Number of steps ahead (k) for expectations. \\
\hline
{\em filter\+Seq} & Vector in which the expected emission sequence will be stored. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1hmm_1_1HMMRegression_a5e7c4dbe9cfacdf2746e92cd20aa2a66}} 
\index{HMMRegression@{HMMRegression}!LogLikelihood@{LogLikelihood}}
\index{LogLikelihood@{LogLikelihood}!HMMRegression@{HMMRegression}}
\doxysubsubsection{LogLikelihood()}
{\footnotesize\ttfamily double Log\+Likelihood (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{predictors,  }\item[{const arma\+::vec \&}]{responses }\end{DoxyParamCaption}) const}



Compute the log-\/likelihood of the given predictors and responses. 


\begin{DoxyParams}{Parameters}
{\em predictors} & Vector of predictor sequences. \\
\hline
{\em responses} & Vector of response sequences. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
Log-\/likelihood of the given sequence. 
\end{DoxyReturn}
\mbox{\label{classmlpack_1_1hmm_1_1HMMRegression_a039bc421248d00ffae03def696c0cfbd}} 
\index{HMMRegression@{HMMRegression}!Predict@{Predict}}
\index{Predict@{Predict}!HMMRegression@{HMMRegression}}
\doxysubsubsection{Predict()}
{\footnotesize\ttfamily double Predict (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{predictors,  }\item[{const arma\+::vec \&}]{responses,  }\item[{arma\+::\+Row$<$ size\+\_\+t $>$ \&}]{state\+Seq }\end{DoxyParamCaption}) const}



Compute the most probable hidden state sequence for the given predictors and responses, using the Viterbi algorithm, returning the log-\/likelihood of the most likely state sequence. 


\begin{DoxyParams}{Parameters}
{\em predictors} & Vector of predictor sequences. \\
\hline
{\em responses} & Vector of response sequences. \\
\hline
{\em state\+Seq} & Vector in which the most probable state sequence will be stored. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
Log-\/likelihood of most probable state sequence. 
\end{DoxyReturn}
\mbox{\label{classmlpack_1_1hmm_1_1HMMRegression_a5840753ea7eec9a4fd241704de54fa9d}} 
\index{HMMRegression@{HMMRegression}!Smooth@{Smooth}}
\index{Smooth@{Smooth}!HMMRegression@{HMMRegression}}
\doxysubsubsection{Smooth()}
{\footnotesize\ttfamily void Smooth (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{predictors,  }\item[{const arma\+::vec \&}]{responses,  }\item[{arma\+::vec \&}]{smooth\+Seq }\end{DoxyParamCaption}) const}



\doxyref{HMM}{p.}{classmlpack_1_1hmm_1_1HMM} smoothing. 

Computes expected emission at each time conditioned on all observations. That is E\{ Y[t] $\vert$ Y[0], ..., Y[T] \}. The returned matrix has columns equal to the number of observations. Note that the expectation may not be meaningful for discrete emissions.


\begin{DoxyParams}{Parameters}
{\em predictors} & Vector of predictor sequences. \\
\hline
{\em responses} & Vector of response sequences. \\
\hline
{\em smooth\+Seq} & Vector in which the expected emission sequence will be stored. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1hmm_1_1HMMRegression_ac4492ef2dc3b4ec02d4ce6ddb3a4171e}} 
\index{HMMRegression@{HMMRegression}!Train@{Train}}
\index{Train@{Train}!HMMRegression@{HMMRegression}}
\doxysubsubsection{Train()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily void Train (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ arma\+::mat $>$ \&}]{predictors,  }\item[{const std\+::vector$<$ arma\+::vec $>$ \&}]{responses }\end{DoxyParamCaption})}



Train the model using the Baum-\/\+Welch algorithm, with only the given predictors and responses. 

Instead of giving a guess transition and emission here, do that in the constructor. Each matrix in the vector of predictors corresponds to an individual data sequence, and likewise for each vec in the vector of responses. The number of rows in each matrix of predictors plus one should be equal to the dimensionality of the \doxyref{HMM}{p.}{classmlpack_1_1hmm_1_1HMM} (which is set in the constructor).

It is preferable to use the other overload of \doxyref{Train()}{p.}{classmlpack_1_1hmm_1_1HMMRegression_ac4492ef2dc3b4ec02d4ce6ddb3a4171e}, with labeled data. That will produce much better results. However, if labeled data is unavailable, this will work. In addition, it is possible to use \doxyref{Train()}{p.}{classmlpack_1_1hmm_1_1HMMRegression_ac4492ef2dc3b4ec02d4ce6ddb3a4171e} with labeled data first, and then continue to train the model using this overload of \doxyref{Train()}{p.}{classmlpack_1_1hmm_1_1HMMRegression_ac4492ef2dc3b4ec02d4ce6ddb3a4171e} with unlabeled data.

The tolerance of the Baum-\/\+Welch algorithm can be set either in the constructor or with the \doxyref{Tolerance()}{p.}{classmlpack_1_1hmm_1_1HMM_a3d9fac84af16250f5a3689692e8f2173} method. When the change in log-\/likelihood of the model between iterations is less than the tolerance, the Baum-\/\+Welch algorithm terminates.

\begin{DoxyNote}{Note}
\doxyref{Train()}{p.}{classmlpack_1_1hmm_1_1HMMRegression_ac4492ef2dc3b4ec02d4ce6ddb3a4171e} can be called multiple times with different sequences; each time it is called, it uses the current parameters of the \doxyref{HMM}{p.}{classmlpack_1_1hmm_1_1HMM} as a starting point for training.
\end{DoxyNote}

\begin{DoxyParams}{Parameters}
{\em predictors} & Vector of predictor sequences. \\
\hline
{\em responses} & Vector of response sequences. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1hmm_1_1HMMRegression_a9d049da300ddcf8b1c38a1e63c93bf2e}} 
\index{HMMRegression@{HMMRegression}!Train@{Train}}
\index{Train@{Train}!HMMRegression@{HMMRegression}}
\doxysubsubsection{Train()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily void Train (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ arma\+::mat $>$ \&}]{predictors,  }\item[{const std\+::vector$<$ arma\+::vec $>$ \&}]{responses,  }\item[{const std\+::vector$<$ arma\+::\+Row$<$ size\+\_\+t $>$ $>$ \&}]{state\+Seq }\end{DoxyParamCaption})}



Train the model using the given labeled observations; the transition and regression emissions are directly estimated. 

Each matrix in the vector of predictors corresponds to an individual data sequence, and likewise for each vec in the vector of responses. The number of rows in each matrix of predictors plus one should be equal to the dimensionality of the \doxyref{HMM}{p.}{classmlpack_1_1hmm_1_1HMM} (which is set in the constructor).

\begin{DoxyNote}{Note}
\doxyref{Train()}{p.}{classmlpack_1_1hmm_1_1HMMRegression_ac4492ef2dc3b4ec02d4ce6ddb3a4171e} can be called multiple times with different sequences; each time it is called, it uses the current parameters of the HMMR as a starting point for training.
\end{DoxyNote}

\begin{DoxyParams}{Parameters}
{\em predictors} & Vector of predictor sequences. \\
\hline
{\em responses} & Vector of response sequences. \\
\hline
{\em state\+Seq} & Vector of state sequences, corresponding to each observation. \\
\hline
\end{DoxyParams}


The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
/home/aakash/mlpack/src/mlpack/methods/hmm/\textbf{ hmm\+\_\+regression.\+hpp}\end{DoxyCompactItemize}
