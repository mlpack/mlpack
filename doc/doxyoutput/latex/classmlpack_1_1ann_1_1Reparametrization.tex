\doxysection{Reparametrization$<$ Input\+Data\+Type, Output\+Data\+Type $>$ Class Template Reference}
\label{classmlpack_1_1ann_1_1Reparametrization}\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}


Implementation of the \doxyref{Reparametrization}{p.}{classmlpack_1_1ann_1_1Reparametrization} layer class.  


\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\textbf{ Reparametrization} ()
\begin{DoxyCompactList}\small\item\em Create the \doxyref{Reparametrization}{p.}{classmlpack_1_1ann_1_1Reparametrization} object. \end{DoxyCompactList}\item 
\textbf{ Reparametrization} (const \textbf{ Reparametrization} \&layer)
\begin{DoxyCompactList}\small\item\em Copy Constructor. \end{DoxyCompactList}\item 
\textbf{ Reparametrization} (const size\+\_\+t latent\+Size, const bool stochastic=true, const bool include\+Kl=true, const double beta=1)
\begin{DoxyCompactList}\small\item\em Create the \doxyref{Reparametrization}{p.}{classmlpack_1_1ann_1_1Reparametrization} layer object using the specified sample vector size. \end{DoxyCompactList}\item 
\textbf{ Reparametrization} (\textbf{ Reparametrization} \&\&layer)
\begin{DoxyCompactList}\small\item\em Move Constructor. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename eT $>$ }\\void \textbf{ Backward} (const arma\+::\+Mat$<$ eT $>$ \&input, const arma\+::\+Mat$<$ eT $>$ \&gy, arma\+::\+Mat$<$ eT $>$ \&g)
\begin{DoxyCompactList}\small\item\em Ordinary feed backward pass of a neural network, calculating the function f(x) by propagating x backwards trough f. \end{DoxyCompactList}\item 
double \textbf{ Beta} () const
\begin{DoxyCompactList}\small\item\em Get the value of the beta hyperparameter. \end{DoxyCompactList}\item 
Output\+Data\+Type \& \textbf{ Delta} ()
\begin{DoxyCompactList}\small\item\em Modify the delta. \end{DoxyCompactList}\item 
Output\+Data\+Type const  \& \textbf{ Delta} () const
\begin{DoxyCompactList}\small\item\em Get the delta. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename eT $>$ }\\void \textbf{ Forward} (const arma\+::\+Mat$<$ eT $>$ \&input, arma\+::\+Mat$<$ eT $>$ \&output)
\begin{DoxyCompactList}\small\item\em Ordinary feed forward pass of a neural network, evaluating the function f(x) by propagating the activity forward through f. \end{DoxyCompactList}\item 
bool \textbf{ Include\+KL} () const
\begin{DoxyCompactList}\small\item\em Get the value of the include\+Kl parameter. \end{DoxyCompactList}\item 
size\+\_\+t \textbf{ Input\+Shape} () const
\item 
double \textbf{ Loss} ()
\begin{DoxyCompactList}\small\item\em Get the KL divergence with standard normal. \end{DoxyCompactList}\item 
\textbf{ Reparametrization} \& \textbf{ operator=} (const \textbf{ Reparametrization} \&layer)
\begin{DoxyCompactList}\small\item\em Copy assignment operator. \end{DoxyCompactList}\item 
\textbf{ Reparametrization} \& \textbf{ operator=} (\textbf{ Reparametrization} \&\&layer)
\begin{DoxyCompactList}\small\item\em Move assignment operator. \end{DoxyCompactList}\item 
Output\+Data\+Type \& \textbf{ Output\+Parameter} ()
\begin{DoxyCompactList}\small\item\em Modify the output parameter. \end{DoxyCompactList}\item 
Output\+Data\+Type const  \& \textbf{ Output\+Parameter} () const
\begin{DoxyCompactList}\small\item\em Get the output parameter. \end{DoxyCompactList}\item 
size\+\_\+t \& \textbf{ Output\+Size} ()
\begin{DoxyCompactList}\small\item\em Modify the output size. \end{DoxyCompactList}\item 
size\+\_\+t const  \& \textbf{ Output\+Size} () const
\begin{DoxyCompactList}\small\item\em Get the output size. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Archive $>$ }\\void \textbf{ serialize} (Archive \&ar, const uint32\+\_\+t)
\begin{DoxyCompactList}\small\item\em Serialize the layer. \end{DoxyCompactList}\item 
bool \textbf{ Stochastic} () const
\begin{DoxyCompactList}\small\item\em Get the value of the stochastic parameter. \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\subsubsection*{template$<$typename Input\+Data\+Type = arma\+::mat, typename Output\+Data\+Type = arma\+::mat$>$\newline
class mlpack\+::ann\+::\+Reparametrization$<$ Input\+Data\+Type, Output\+Data\+Type $>$}

Implementation of the \doxyref{Reparametrization}{p.}{classmlpack_1_1ann_1_1Reparametrization} layer class. 

This layer samples from the given parameters of a normal distribution.

This class also supports beta-\/\+VAE, a state-\/of-\/the-\/art framework for automated discovery of interpretable factorised latent representations from raw image data in a completely unsupervised manner.

For more information, refer the following paper.


\begin{DoxyCode}{0}
\DoxyCodeLine{@article\{ICLR2017,}
\DoxyCodeLine{  title   = \{beta-\/VAE: Learning basic visual concepts with a constrained}
\DoxyCodeLine{             variational framework\},}
\DoxyCodeLine{  author  = \{Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess,}
\DoxyCodeLine{             Xavier Glorot, Matthew Botvinick, Shakir Mohamed and}
\DoxyCodeLine{             Alexander Lerchner | Google DeepMind\},}
\DoxyCodeLine{  journal = \{2017 International Conference on Learning Representations(ICLR)\},}
\DoxyCodeLine{  year    = \{2017\},}
\DoxyCodeLine{  url     = \{https:\textcolor{comment}{//deepmind.com/research/publications/beta-\/VAE-\/Learning-\/Basic-\/Visual-\/Concepts-\/with-\/a-\/Constrained-\/Variational-\/Framework\}}}
\DoxyCodeLine{\}}

\end{DoxyCode}



\begin{DoxyTemplParams}{Template Parameters}
{\em Input\+Data\+Type} & Type of the input data (arma\+::colvec, arma\+::mat, arma\+::sp\+\_\+mat or arma\+::cube). \\
\hline
{\em Output\+Data\+Type} & Type of the output data (arma\+::colvec, arma\+::mat, arma\+::sp\+\_\+mat or arma\+::cube). \\
\hline
\end{DoxyTemplParams}


Definition at line 56 of file reparametrization.\+hpp.



\doxysubsection{Constructor \& Destructor Documentation}
\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_a832fbcfd05acf9e46e104c51db19588f}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!Reparametrization@{Reparametrization}}
\index{Reparametrization@{Reparametrization}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{Reparametrization()\hspace{0.1cm}{\footnotesize\ttfamily [1/4]}}
{\footnotesize\ttfamily \textbf{ Reparametrization} (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}



Create the \doxyref{Reparametrization}{p.}{classmlpack_1_1ann_1_1Reparametrization} object. 

\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_a4a8caf58b20566b71a6a9782211b8121}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!Reparametrization@{Reparametrization}}
\index{Reparametrization@{Reparametrization}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{Reparametrization()\hspace{0.1cm}{\footnotesize\ttfamily [2/4]}}
{\footnotesize\ttfamily \textbf{ Reparametrization} (\begin{DoxyParamCaption}\item[{const size\+\_\+t}]{latent\+Size,  }\item[{const bool}]{stochastic = {\ttfamily true},  }\item[{const bool}]{include\+Kl = {\ttfamily true},  }\item[{const double}]{beta = {\ttfamily 1} }\end{DoxyParamCaption})}



Create the \doxyref{Reparametrization}{p.}{classmlpack_1_1ann_1_1Reparametrization} layer object using the specified sample vector size. 


\begin{DoxyParams}{Parameters}
{\em latent\+Size} & The number of output latent units. \\
\hline
{\em stochastic} & Whether we want random sample or constant. \\
\hline
{\em include\+Kl} & Whether we want to include KL loss in backward function. \\
\hline
{\em beta} & The beta (hyper)parameter for beta-\/\+VAE mentioned above. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_a4eaa387debbde852c4d784cc84764ca9}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!Reparametrization@{Reparametrization}}
\index{Reparametrization@{Reparametrization}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{Reparametrization()\hspace{0.1cm}{\footnotesize\ttfamily [3/4]}}
{\footnotesize\ttfamily \textbf{ Reparametrization} (\begin{DoxyParamCaption}\item[{const \textbf{ Reparametrization}$<$ Input\+Data\+Type, Output\+Data\+Type $>$ \&}]{layer }\end{DoxyParamCaption})}



Copy Constructor. 

\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_a3394d24a1c604b51a7cde3ede5554af9}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!Reparametrization@{Reparametrization}}
\index{Reparametrization@{Reparametrization}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{Reparametrization()\hspace{0.1cm}{\footnotesize\ttfamily [4/4]}}
{\footnotesize\ttfamily \textbf{ Reparametrization} (\begin{DoxyParamCaption}\item[{\textbf{ Reparametrization}$<$ Input\+Data\+Type, Output\+Data\+Type $>$ \&\&}]{layer }\end{DoxyParamCaption})}



Move Constructor. 



\doxysubsection{Member Function Documentation}
\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_a78dbad83871f43db1975e45a9a69c376}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!Backward@{Backward}}
\index{Backward@{Backward}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{Backward()}
{\footnotesize\ttfamily void Backward (\begin{DoxyParamCaption}\item[{const arma\+::\+Mat$<$ eT $>$ \&}]{input,  }\item[{const arma\+::\+Mat$<$ eT $>$ \&}]{gy,  }\item[{arma\+::\+Mat$<$ eT $>$ \&}]{g }\end{DoxyParamCaption})}



Ordinary feed backward pass of a neural network, calculating the function f(x) by propagating x backwards trough f. 

Using the results from the feed forward pass.


\begin{DoxyParams}{Parameters}
{\em input} & The propagated input activation. \\
\hline
{\em gy} & The backpropagated error. \\
\hline
{\em g} & The calculated gradient. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_ad1b9206255af52171cb88dfb7c326576}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!Beta@{Beta}}
\index{Beta@{Beta}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{Beta()}
{\footnotesize\ttfamily double Beta (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the value of the beta hyperparameter. 



Definition at line 143 of file reparametrization.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_ad6601342d560219ce951d554e69e5e87}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!Delta@{Delta}}
\index{Delta@{Delta}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{Delta()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily Output\+Data\+Type\& Delta (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the delta. 



Definition at line 119 of file reparametrization.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_a797f7edb44dd081e5e2b3cc316eef6bd}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!Delta@{Delta}}
\index{Delta@{Delta}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{Delta()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily Output\+Data\+Type const\& Delta (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the delta. 



Definition at line 117 of file reparametrization.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_a461f849bc638c15bec262dc9c3a58abe}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!Forward@{Forward}}
\index{Forward@{Forward}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{Forward()}
{\footnotesize\ttfamily void Forward (\begin{DoxyParamCaption}\item[{const arma\+::\+Mat$<$ eT $>$ \&}]{input,  }\item[{arma\+::\+Mat$<$ eT $>$ \&}]{output }\end{DoxyParamCaption})}



Ordinary feed forward pass of a neural network, evaluating the function f(x) by propagating the activity forward through f. 


\begin{DoxyParams}{Parameters}
{\em input} & Input data used for evaluating the specified function. \\
\hline
{\em output} & Resulting output activation. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_aa00a2f9218830aaa49f635ad7925d3dc}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!IncludeKL@{IncludeKL}}
\index{IncludeKL@{IncludeKL}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{IncludeKL()}
{\footnotesize\ttfamily bool Include\+KL (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the value of the include\+Kl parameter. 



Definition at line 140 of file reparametrization.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_a13ab93f234244a68f6ade76287284447}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!InputShape@{InputShape}}
\index{InputShape@{InputShape}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{InputShape()}
{\footnotesize\ttfamily size\+\_\+t Input\+Shape (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Definition at line 145 of file reparametrization.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_a97c2b4c73f25bb50e148d8e4febeda24}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!Loss@{Loss}}
\index{Loss@{Loss}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{Loss()}
{\footnotesize\ttfamily double Loss (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Get the KL divergence with standard normal. 



Definition at line 127 of file reparametrization.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_aa5adae8ce8541d66621702dafd5031c2}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!operator=@{operator=}}
\index{operator=@{operator=}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{operator=()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \textbf{ Reparametrization}\& operator= (\begin{DoxyParamCaption}\item[{const \textbf{ Reparametrization}$<$ Input\+Data\+Type, Output\+Data\+Type $>$ \&}]{layer }\end{DoxyParamCaption})}



Copy assignment operator. 

\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_aa6b3334aa4e5b95e293b0c3af2c83964}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!operator=@{operator=}}
\index{operator=@{operator=}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{operator=()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \textbf{ Reparametrization}\& operator= (\begin{DoxyParamCaption}\item[{\textbf{ Reparametrization}$<$ Input\+Data\+Type, Output\+Data\+Type $>$ \&\&}]{layer }\end{DoxyParamCaption})}



Move assignment operator. 

\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_a21d5f745f02c709625a4ee0907f004a5}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!OutputParameter@{OutputParameter}}
\index{OutputParameter@{OutputParameter}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{OutputParameter()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily Output\+Data\+Type\& Output\+Parameter (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the output parameter. 



Definition at line 114 of file reparametrization.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_a0ee21c2a36e5abad1e7a9d5dd00849f9}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!OutputParameter@{OutputParameter}}
\index{OutputParameter@{OutputParameter}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{OutputParameter()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily Output\+Data\+Type const\& Output\+Parameter (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the output parameter. 



Definition at line 112 of file reparametrization.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_a419dbf849d95d9955d055a2e6ba321d2}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!OutputSize@{OutputSize}}
\index{OutputSize@{OutputSize}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{OutputSize()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily size\+\_\+t\& Output\+Size (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the output size. 



Definition at line 124 of file reparametrization.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_a004c01f91ccd1863b8df0ab76ab4aa6a}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!OutputSize@{OutputSize}}
\index{OutputSize@{OutputSize}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{OutputSize()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily size\+\_\+t const\& Output\+Size (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the output size. 



Definition at line 122 of file reparametrization.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_a65cba07328997659bec80b9879b15a51}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!serialize@{serialize}}
\index{serialize@{serialize}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{serialize()}
{\footnotesize\ttfamily void serialize (\begin{DoxyParamCaption}\item[{Archive \&}]{ar,  }\item[{const uint32\+\_\+t}]{ }\end{DoxyParamCaption})}



Serialize the layer. 

\mbox{\label{classmlpack_1_1ann_1_1Reparametrization_ae0147f929967eaddb678cf7d07115d3c}} 
\index{Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}!Stochastic@{Stochastic}}
\index{Stochastic@{Stochastic}!Reparametrization$<$ InputDataType, OutputDataType $>$@{Reparametrization$<$ InputDataType, OutputDataType $>$}}
\doxysubsubsection{Stochastic()}
{\footnotesize\ttfamily bool Stochastic (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the value of the stochastic parameter. 



Definition at line 137 of file reparametrization.\+hpp.



The documentation for this class was generated from the following files\+:\begin{DoxyCompactItemize}
\item 
/home/aakash/mlpack/src/mlpack/methods/ann/layer/\textbf{ layer\+\_\+types.\+hpp}\item 
/home/aakash/mlpack/src/mlpack/methods/ann/layer/\textbf{ reparametrization.\+hpp}\end{DoxyCompactItemize}
